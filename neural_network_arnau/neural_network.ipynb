{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('movie_metadata.csv')\n",
    "data_useful = data[['budget', 'duration','director_facebook_likes','actor_1_facebook_likes','actor_2_facebook_likes','actor_3_facebook_likes','gross','imdb_score','title_year','aspect_ratio','cast_total_facebook_likes','facenumber_in_poster']]\n",
    "data_useful = data_useful.drop(['gross'], axis = 1)\n",
    "data_useful = data_useful.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_together(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "    permutation = np.random.permutation(len(a))\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_a[new_index] = a[old_index]\n",
    "        shuffled_b[new_index] = b[old_index]\n",
    "    return shuffled_a, shuffled_b\n",
    "\n",
    "def order_score(a,b):\n",
    "    assert len(a)==len(b)\n",
    "    new_a = np.empty(a.shape, dtype=a.dtype)\n",
    "    new_b = np.empty(b.shape, dtype=b.dtype)\n",
    "    maxim = max(b)\n",
    "    for i in range(len(b)):\n",
    "        ind = np.argmin(b)\n",
    "        new_b[i] = b[ind]\n",
    "        new_a[i] = a[ind]\n",
    "        b[ind] = maxim + 1\n",
    "    return new_a, new_b\n",
    "\n",
    "def prep_data(num_classes, test_data_perc, data_useful, verbose = 1):\n",
    "    x_not_norm = np.array(data_useful.drop(['imdb_score'], axis=1))\n",
    "    y_not_norm = np.array(data_useful['imdb_score'])\n",
    "    [x_not_norm, y_not_norm] = order_score(x_not_norm, y_not_norm)\n",
    "\n",
    "    # Network Parameters\n",
    "    num_films = np.shape(x_not_norm)[0]\n",
    "    num_input = np.shape(x_not_norm)[1] # number of inputs\n",
    "\n",
    "    # Normalise data\n",
    "    x = np.zeros(np.shape(x_not_norm))\n",
    "    for i in range(num_input):\n",
    "        maxim = max(x_not_norm[:, i]) \n",
    "        minim = min(x_not_norm[:, i]) \n",
    "        x[:,i] = (x_not_norm[:, i] - minim) / (maxim - minim)\n",
    "    if verbose:\n",
    "        print('x = ', np.shape(x))\n",
    "    \n",
    "    films_per_class = int(num_films / num_classes) + 1\n",
    "    y = np.zeros(len(y_not_norm))\n",
    "    y = y.astype(int)\n",
    "    for i in range(len(y)):\n",
    "        y[i] = int(i / films_per_class)\n",
    "    if verbose:\n",
    "        print('y = ', np.shape(y))\n",
    "    \n",
    "    score_separation = np.zeros(num_classes + 1)\n",
    "    score_separation[num_classes] = 10\n",
    "    for i in range(num_classes):\n",
    "        score_separation[i] = y_not_norm[i*films_per_class+1]\n",
    "    \n",
    "#     score_separation = 10 / num_classes\n",
    "#     y = np.zeros(len(y_not_norm))\n",
    "#     y = y.astype(int)\n",
    "#     for i in range(len(y)):\n",
    "#         y[i] = int(y_not_norm[i] / score_separation)\n",
    "#     print('y = ', np.shape(y))\n",
    "\n",
    "\n",
    "        \n",
    "    [x, y] = shuffle_together(x, y)\n",
    "\n",
    "    x_train = x[:int( (1-test_data_perc) * len(x))]\n",
    "    x_test  = x[len(x_train):]\n",
    "    y_train = y[:len(x_train)]\n",
    "    y_test  = y[len(x_train):]\n",
    "\n",
    "    if verbose:\n",
    "        print('x_train = ', np.shape(x_train))\n",
    "        print('x_test = ', np.shape(x_test))\n",
    "\n",
    "        counts = np.bincount(y_train)\n",
    "        for i in range(num_classes):\n",
    "            print('films ', score_separation[i], 'to', score_separation[i+1],\n",
    "                  ' -> ', counts[i]/len(y_train)*100)\n",
    "\n",
    "    return [num_input, x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  (4293, 10)\n",
      "y =  (4293,)\n",
      "x_train =  (3863, 10)\n",
      "x_test =  (430, 10)\n",
      "films  1.9 to 6.6  ->  49.469324359306235\n",
      "films  6.6 to 10.0  ->  50.53067564069376\n",
      "430/430 [==============================] - 1s 2ms/sample - loss: 0.6329 - acc: 0.6465\n",
      "1 REPS DONE\n",
      "x =  (4293, 10)\n",
      "y =  (4293,)\n",
      "x_train =  (3863, 10)\n",
      "x_test =  (430, 10)\n",
      "films  1.9 to 6.6  ->  50.064716541548016\n",
      "films  6.6 to 10.0  ->  49.93528345845198\n",
      "430/430 [==============================] - 1s 2ms/sample - loss: 0.6707 - acc: 0.5767\n",
      "2 REPS DONE\n",
      "x =  (4293, 10)\n",
      "y =  (4293,)\n",
      "x_train =  (3863, 10)\n",
      "x_test =  (430, 10)\n",
      "films  1.9 to 6.6  ->  49.90939684183277\n",
      "films  6.6 to 10.0  ->  50.09060315816723\n",
      "430/430 [==============================] - 1s 2ms/sample - loss: 0.6399 - acc: 0.6302\n",
      "3 REPS DONE\n",
      "x =  (4293, 10)\n",
      "y =  (4293,)\n",
      "x_train =  (3863, 10)\n",
      "x_test =  (430, 10)\n",
      "films  1.9 to 6.6  ->  50.349469324359305\n",
      "films  6.6 to 10.0  ->  49.650530675640695\n",
      "430/430 [==============================] - 1s 2ms/sample - loss: 0.6388 - acc: 0.6209\n",
      "4 REPS DONE\n",
      "x =  (4293, 10)\n",
      "y =  (4293,)\n",
      "x_train =  (3863, 10)\n",
      "x_test =  (430, 10)\n",
      "films  1.9 to 6.6  ->  50.220036241263266\n",
      "films  6.6 to 10.0  ->  49.779963758736734\n",
      "430/430 [==============================] - 1s 2ms/sample - loss: 0.6442 - acc: 0.6349\n",
      "5 REPS DONE\n",
      "accuracy =  0.6218604683876038\n",
      "loss =  0.645280154250389\n",
      "percentage of films per category =  0.5\n"
     ]
    }
   ],
   "source": [
    "reps = 5\n",
    "acc = 0\n",
    "loss = 0\n",
    "num_classes = 2 # How many score divisions we want\n",
    "ep = 5 # Epochs per repetition\n",
    "neu = 20 # Neurons in mid layers\n",
    "for i in range(reps):\n",
    "    [num_input, x_train, y_train, x_test, y_test] = prep_data(num_classes, .1, data_useful, verbose = 1)\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(num_input, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(neu, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(num_classes, activation=tf.nn.sigmoid)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                           loss='sparse_categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=ep, verbose = 0)\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    acc += test_acc\n",
    "    loss += test_loss\n",
    "    print(i + 1, 'REPS DONE')\n",
    "    \n",
    "print('accuracy = ', acc / reps)\n",
    "print('loss = ', loss / reps)\n",
    "print('percentage of films per category = ', 1/num_classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
